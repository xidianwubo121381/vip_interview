### my interview
---------------------
> **京东到家一面**

- 你觉得哪个项目最重要，介绍一下？
- 介绍下XGB的原理
- 特征选择是如何做的？
- Item特征用的不多，文本特征有用到吗？有交叉特征吗？深度模型是怎么用的？（LSTM）
- 和其他部门或业务方沟通，沟通的效率和方式，这块有没有什么心得？


- 提到用到了spark，了解数据倾斜吗？数据倾斜了要怎么处理？为什么会出现数据倾斜，请列举几个场景

    https://blog.csdn.net/meihao5/article/details/81084876


- id类特征是如何处理的，例如用户id，有用过哈希分桶吗？

- 实时特征有哪些？有用到kafka（例如利用客户端日志）做实时特征吗？

    实时特征一般是来源于画像或自己保存到redis中，没有用kafka

- code-1：链表反转
- code-2：链表反转进阶，给定整数left和right，求反转后的链表，例如1-2-3-4-5 left=2，right=4，输出为：1-4-3-2-5

> **京东到家二面**

- 搜索和排序了解吗
- 聊项目比较多，很宽很发散


-------------------------
> **滴滴金融事业部一面**

- 介绍一个项目
- 特征选择？文本特征是如何处理的？word2vec是怎么处理文本特征的？
- xgb的正则化公式？
- 什么是方差和偏差？
- xgb是boosting模型，它的基分类器一般是弱分类器，可以是强分类器吗？这样做有什么优点和缺点？
- 随机森林解决的是方差还是偏差问题？随机森林这种bagging模型的基分类器，也能使用强分类器吗？有什么缺点？（从偏差和方差的角度考虑）

**类似问题：随机森林的基分类器可否由决策树替换为线性分类器或者K-NN？**
```
随机森林（Random Forest）
随机森林（RF）是Bagging算法族中的一种，RF是以决策树为基分类器构建Bagging集成的基础上，进一步在决策树的训练过程中引入随机属性选择。

具体来说：传统决策树在选择划分属性时是在当前结点的属性集合（假设有d个属性）中选择一个最优属性；而在RF中，对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含k个属性的子集，然后再从这个子集中选择一个最优属性用于划分。

即RF中的基学习器的多样性不进来自样本扰动，还来自属性扰动。

方差-偏差
从方差-偏差角度来说，Bagging算法主要是降低方差，即RF测试结果的方差比每一个基学习器的方差要小！！

解答
Bagging所采用的基分类器，最好是对样本分布比较敏感（即就是 不稳定的分类器）。

线性分类器或者K-NN都是比较稳定的算法，对异常点不敏感，并且本身方差就不大，所以用它们做基分类器使用Bagging并不能在原有基础上获得好的结果，甚至，因为Bagging的采样，而导致它们在训练中难以收敛，从而增大了集成分类的偏差！！！
————————————————
版权声明：本文为CSDN博主「还没想好116」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/weixin_44177568/article/details/99706238
```

- FM是如何学习隐向量的？
- lstm有几个门？公式分别是？
- ctr场景下，如果要使用lstm模型做预测，数据集应该是什么样子的，即如何构造label呢？（有监督，肯定需要构造特征和标签，具体格式应该是什么样子的）
- code：两数之和，输出下标之和的最小值。（主要看编码格式和风格）
```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-


def two_sum(nums, target):
    sum = len(nums) * 3
    num_dict = dict()
    for i in range(len(nums)):
        num_dict[nums[i]] = i

    for i in range(len(nums)):
        other = target - nums[i]
        if num_dict.get(other):
            sum = min(sum, i + num_dict.get(other))

    return 0 if sum == len(nums) * 3 else sum


nums = [1, 8, 3, 2, 4, 5, 6, 7]
target = 11
print two_sum(nums, target)

```

> **滴滴金融事业部二面**

- 聊项目，发散思维


---------------------------
> **得到APP一面**

- 介绍一个项目
- 特征有具体哪些？有哪些类别，详细介绍
- 协同过滤了解吗？不使用矩阵，直接用hive sql 简单的操作，如何实现协同过滤，举个例子，表中有3条数据，共两列，分别是：用户1、语文；用户2、语文；用户2、数学，如何得到用户1、数学？（提示：join）
- 得到现在用的都是深度模型，深度模型了解吗，用的多吗？
- 模型是如何上线的，更新频次是什么？对应的离线特征是怎么做的，来源于埋点、数仓？
- 有用过mongodb数据库吗？

> **得到APP二面**

- 如何计算物品之间的相似度？
- 时序的特征有用到吗？怎么用？
- 商品有各种各样的标签，如何根据标签计算商品的相似度？
- item to item的模型除了协同过滤还有哪些？（embedding、知识图谱）
- 大数据工具了解吗，哪个用的比较多？
- 推荐的多路召回，每一路的原因和原理，为什么要加入某路召回；做算法更重要的是敏锐性，为什么要加入某个策略
- 了解hmm模型吗？知识图谱？
- 工作中的亮点和难点各列举一个
- 有用过得到APP吗，针对推荐有什么建议？


- 为什么不用Youtube那个模型？协同过滤或者传统模型太古老了

回答说深度上线工程复杂，又问复杂在哪里？为什么不能上？


- nlp相关的内容或模型了解哪些？
- 搜索有纠错吗？例如query中某个字打错了但是拼音是对的，支持拼音搜索吗，如何做的？
- es用的什么版本？分词器？了解分词的原理吗？
- 除了这些，还有哪些我没问到的，你觉得自己比较擅长或者熟悉的模型、工具等等？
- 推荐场景比较多，和ctr不是很match，问了很多推荐和nlp的东西
- from 面试官：算法工程师其实对工程能力要求很高，因为模型有很多库可用或者原理实现即可，关键在于如何把数据送到模型中，在于数据的获取和数据，以及一些规则策略（规则可能很有效，但关键是如何发现和制定好的策略，要敏锐），因此对大数据或者工程的要求比较高


---------------------
> **Soul一面**

- LR的损失函数是什么？写一下公式（交叉熵）
- LR为什么用交叉熵作为损失函数，而不用平方差？
https://www.jianshu.com/p/6a7d3f26f003
- sigmoid函数有什么缺点？
- XGB和GBDT的区别？
- XGB能够输出特征的重要程度，是怎么计算的？
- 求编辑距离的复杂度？
- 特征维度，类别特征是如何处理的，除了one-hot，有用到其他吗例如Embedding？
- es的BM25算法和TF-IDF的区别？
- CNN和LSTM的区别和适用场景？哪个的计算量更大？（例如使用GPU跑模型时，能并行的可以并行，那么CNN和LSTM哪个计算复杂度更高，为什么？）


----------------------
> **美团买菜一面**

- Skip-gram和CBOW了解吗
- XGB的特征重要性是怎么算的？
- XGB调参有哪些？
- 代码题1:最长公共子序列
- 代码题2:有序数组（元素可以重复），查找指定元素第一次出现的位置
- 代码题3:反转链表



------------------------------------------------------------
### others interview
-------------------
> **映客直播二面**

- 常用的优化器有哪些？sgd，动量梯度下降，adam

- xgb和随机森林缩小方差和偏差角度怎么理解？

  随机森林是bagging的思想，采样出不同的样本训练出不同的模型，通过投票的方式，综合获得模型输出结果，主要是为了减少样本的方差。

  xgb是boosting的思想，利用残差依次串行训练出模型，综合各个模型的结果累加成最后的输出结果，主要是减少了样本的偏差。

  偏差是模型输出结果的均值与样本真实值之间的差值。

  方差是模型输出结果的方差。

- id类特征做embedding，用tf怎么写，底层是怎么实现的？

- lstm和gru有什么区别？

- spark调优做过哪些？

  分配更多的资源，例如：executor memory的运行内存大小

- stream对接的上下游数据源是哪些？

- 写redis需要注意些什么？
  - 注意写入redis的数据的key的量级，如果很多，需要通过mset来写入，这样就不能设置过期时间，需要将这些key记录下来；
  - 一般写入redis中的key都有过期时间；
  - 工程上一般只使用string类型的数据，原因是这种类型操作起来读取速度是最快的，但是有隐藏的大key问题，value值太大（一般不能超过10kb），会降低redis读取的速度。

- hadoop put操作的底层原理？

- 数据倾斜一般怎么办？

  一般导致数据倾斜的原因是执行了shuffle操作，而产生shuffle操作的行为是：**groupByKey**、**countByKey**、**reduceByKey**、**join**

  https://zhuanlan.zhihu.com/p/64240857

- 决策树如何建树的？如果不限制树的深度，叶子节点数量，还会有哪些条件让树终止？

  决策树是从根节点开始，每次对一个叶子节点，选取一个最优分割点对样本集进行划分，建树。不同的算法准则有不同的划分方式。

  ID3选取信息增益，C4.5克服了信息增益中的偏向于选取值较多的特征的信息增益比，Cart算法选取的是基尼指数和平方误差。

  叶子结点都是同一种类别也就可以终止划分。

  叶节点的继续划分，没能提高模型的泛化能力就可以停止划分。

- xgb是如何查找分裂点的？

  XGBoost在训练前预先将特征按照特征值进行了排序，并存储为block结构，以后在结点分裂时可以重复使用该结构。

  因此，可以采用特征并行的方法利用多个线程分别计算每个特征的最佳分割点，根据每次分裂后产生的增益，最终选择增益最大的那个特征的特征值作为最佳分裂点。

- itemCF和矩阵分解有什么区别？矩阵分解了解哪些？

  
  相比协同过滤，矩阵分解的优点有：

  矩阵分解的优点：

  （1）泛化能力强。在一定程度上解决了数据稀疏问题
  （2）空间复杂度低。无需存储协同过滤模型服务阶段所需的“庞大”的用户相似性或物品相似性矩阵，只需存储用户和物品隐向量。空间复杂度由𝑛^2级别降低到(𝑛+𝑚)∙𝑘级别。
  （3）更好的扩展性和灵活性。矩阵分解的最终产出是用户和物品隐向量，与深度学习的Embedding思想不谋而合，因此矩阵分解的结果也非常便于与其他特征进行拼接和组合，便于与深度网络进行无缝结合。

  除上述优点外，矩阵分解同样具有局限性，体现在矩阵分解不方便加入用户、物品及上下文特征，同时在用户历史行为缺失时，无法进行有效推荐。

- itemCF的优缺点？

  ###### 协同过滤优点

  协同推荐是应用最广泛的推荐算法。因为基于内容推荐的算法，需要给物品打上标签，给用户建用户画像，才能实现匹配推荐。相比之下，协同过滤简单了许多。它是仅使用用户行为的进行推荐，我们不需要对物品或信息进行完整的标签化分析，避免了一些人可能难以量化描述的概念的标签构建，又可以很好地发现用户的潜在兴趣偏好。

  ###### 协同过滤缺点

  因为协同过滤依赖用户的历史数据，面对新的用户或者新的物品，在开始的时候没有数据或数据较少时，协同过滤算法无法做出推荐。需要等数据积累，或者其他方案进行弥补缺陷，也就是常说的冷启动的问题。

- 如果打压这种热门数据？

  - 对于评分矩阵中的评分，score* count（total_user）/count(click_item_user)，打击热榜效应

  - 对行为少的不活跃的用户进行过滤，行为少的用户，数据太过于稀疏，召回难度大
  - 对用户中热门物品进行过滤，热门物品可能大部分用户都有过行为
  - 非常活跃的用户，用户协同可能会出现一种情况，就是每个用户的topN相似用户里都有这些非常活跃的用户，所以需要适当过滤掉这些用

- 海量数据里找第k大数？

  https://blog.csdn.net/zyq522376829/article/details/47686867

- 深度学习模型了解哪些？w&d和deepFM一定要说

- FM相对于LR的有点有哪些？

  FM可以看做带特征交叉的LR，模型覆盖了LR的宽模型结构，同时也引入了交叉特征，增加模型的非线性，提升模型容量，能捕捉更多的信息。

  
--- 
> **易车一面**

为啥用lr不用FM？

你了解FM的原理吗？

训练的样本为啥要1:1？

> **易车二面**

代码题：返回最大连续子数组和的下标

介绍一下item_cf算法过程？item_cf怎么打击热榜？

swing召回算法是怎样打击热榜的，原理介绍一下？

离线怎么评估召回通道的效果？

FM的原理是什么，介绍一下？

FM应用到召回上，为什么通过用户向量就可以召回item向量？

FM是用内积求和，为啥要用余弦相似度来计算相似度？这个问题没听懂

深度介绍一下？

激活函数是做什么的？为什么要用激活函数？

什么叫梯度消失？

在梯度回传的过程中，需要用到激活函数的导数


---
> **58一面**

代码题：最长回文字串

spark的数据倾斜问题？

redis get set 数据需要多长时间？

lr一般使用什么优化器？梯度下降或者liblinear

模型迭代过程中，线下auc效果可以，但是线上效果不明显，原因是什么？

查看模型权重，偏向于与item点击数或者点击率相关的特征，偏向于item本身的热度信息，统计item的ctr相关信息，推荐的数据还是偏热榜效应，总结是，item物料之间的信息目前的平台上比较缺失，模型很难学到对应的特征，无法给用户推荐更好的视频，正在做的，通过word2vec获取视频的标题和老师的隐向量，标志视频的唯一性。

itemCF数据量很大的时候怎么解决这个问题？

矩阵的分块乘法

发现页dau和pv大概是什么量级？

你还了解哪些其他的模型？

Word2vec 的哈夫曼树优化和负采样优化是为了解决什么问题？怎么解决的？

L1正则和L2正则的区别？

决策树如何防止过拟合？剪枝，引申到Xgb的剪枝，XGB如何防止过拟合？
```
预剪枝

预剪枝的核心思想是在树中结点进行扩展之前，先计算当前的划分是否能带来模型泛化能力的提升，如果不能，则不再继续生长子树此时可能存在不同类别的样本同时存于结点中，搜照多数投票的原则判断该结点所属类别。预剪枝对于何时停止决策树的生长有以下几种方法：

( 1 ）当树到达一定深度的时候，停止树的主长

( 2 ）当到达当前结点的样本数小于某个阈值的时候，停止树的生长

( 3 ）计算每次分裂对测试集的准确度提升 当小于某个阈值的时不再继续扩展

预剪枝真奇思想直接、算法简单、效率高等特点，适合解决大规模问题，但如何准确地估计何时停止树的生长（即上述方法中的深度或阈值），针对不同问题会有很大差别，需要一定经验判断。且预剪枝存在一定局限性，欠拟合的风险较高，虽然当前的划分会导致测试集准确率降低，但在之后的划分中，准确率可能会高显著上升。

后剪枝

后剪枝的核心思想是让算法生成一棵完全生长的决策树，然后从最底层向上计算是否剪枝。剪枝过程将子树删除 用一个叶子结点苔代，该结点的类别同样按照多数投票的原则进行判断 同样地 后剪枝也可以通过在测试集上的准确率进行判断，如果剪枝过后准确率有所提升，则进行剪枝 相比于预剪枝，后剪枝方法通常可以得到泛化能力更强的决策树，但时间开销会更大。

常见的后剪枝方法包括错误率降低剪枝（ Reduced Error Pruning, REP ）、悲观剪枝（ Pess mistic Error Pruning, PEP ）、代价复杂度剪枝（ Cost Complexity Pruning , CCP ）、最小误差剪枝（ Minimum Error Pruning , MEP ）、 CVP ( Critical Value Pruning ）、 OP ( Optimal Pruning ）等方法，这些剪枝万法各有利弊，关注不同的优化角度，本文选取著名的 CART 剪枝方法 CCP 进行介绍。
```

常用熵的定义？

https://www.cnblogs.com/wkang/p/10068475.html


为什么交叉熵可以作为损失函数？

https://www.zhihu.com/question/65288314/answer/244557337


LSTM介绍一下？LSTM为什么能解决梯度消失问题？

LSTM的三个门：输入门，输出门，遗忘门


深度学习中缓解梯度消失的方法？

https://blog.csdn.net/weixin_46470894/article/details/107145207


常见的激活函数

https://www.cnblogs.com/ziytong/p/12820738.html


FM介绍一下？

https://zhuanlan.zhihu.com/p/58160982

https://mp.weixin.qq.com/s/db3evhvowc7R2WLfTmULgQ

https://zhuanlan.zhihu.com/p/58160982


itemCF怎么做的？

问了deepFM w&d模型

在公司有什么贡献？

为什么要走？

算法题 two_sum


> **58二面**

算法题：最长回文串LeetCode第5题

时间复杂度计算公式？

xgb类别类特征如果放到模型里，会有什么问题？应该怎么处理？

除了itemCF还了解哪些协同过滤？

还了解其他什么模型吗？


---
> **天眼查一面**

代码题：无重复最长子串

xgboost 的优缺点？

这些项目中你有什么优化的点？


---
> **每日优鲜一面**

代码题：实现递增序列（有重复的数字）中，目标数字的范围index。

为什么采用one_hot向量？one_hot向量怎么可以用余弦相似度来计算相似度呢？

word2vec与one_hot 有什么区别？

word2vec有什么了解？CBOW和skip_gram的区别是什么？应用的场景不一样

词袋模型是什么，有了解吗？n_gram有了解吗？

---
> **Boss一面**

挑一个项目介绍一下

为什么选了Xgb，lr，fm什么的有没有尝试？

样本维度和特征维度，为什么维度这么多？

数据分析做的哪些？

特征工程做了哪些？

FM的原理？

为什么想走？

auc是什么，auc的缺点是什么

xgb相比于gbdt，做了哪些优化
```
GBDT在优化时只用了一阶导数，xgboost是对代价函数进行二阶泰勒展开

xgboost在代价函数中加入了正则项，用于控制模型复杂度。正则里包含两项：树的叶子节点个数、每个叶子节点上权重的L2模的平方和

学习率(eta)，xgboost进行完一次迭代后，会将叶子节点的权重乘上该系数，主要为了削弱每棵树的影响（gbdt也有学习率）

列采样，不仅能降低过拟合，还能减少计算，这也是xgb异于gbdt的一个特性

对缺失值的处理。对特征的值有缺失的样本，xgboost能自动学出它的分裂方向 6.xgboost支持并行，xgboost的并行体现在特征粒度上，选择每个特征的最佳分割点可以并行
```

deepfm的deep部分和fm层部分分别是什么作用，loss function是啥 fm部分负责提取低阶特征，赋予模型一定的记忆能力；deep部分负责提取高阶特征，赋予模型一定的泛化能力

xgb的loss 是啥，正则包含哪几部分

从一个k维数组里，找出最大值和最小值，比较次数不能超过1.5k次

相比于SVM，fm交叉特征有一定的泛化，怎么理解 FM 模型会为每个特征都学习一个向量，然后将特征和特征的向量做内积作为交叉特征的权重，即使这个交叉特征没有出现过，也可以对这个交叉特征的权重进行更新。

FM模型的复杂度 FM复杂度是o(n2)，准确的来说是o(kn2)，（其中k是向量长度）。但是针对特征交叉项可以做一系列变换，变换为特征的和的平方减去特征平方和的形式，复杂度降为o(kn)

hive 分组排序 （根据科目分组，按分数排序，科目下边有相同的分数） RANK() 排序相同时会重复，总数不会变 (1,2,3,3,5,6,7) DENSE_RANK() 排序相同时会重复，总数会减少（1,2,3,3,4,5,6） ROW_NUMBER() 会根据顺序计算(1,2,3,4,5,6,7)

deepfm过拟合应该怎么解决，欠拟合应该怎么解决 欠拟合:增加deep部分的层数，增加epoch的轮数，增加learningrate，减少正则化力度 过拟合:在deep层直接增加dropout的率，减少epoch轮数，增加更多的数据，增加正则化力度，shuffle 数据


反问：

你们做什么？偏向算法研究，发论文

线上的模型用哪些？没正面回答，说挺复杂

偏向研究，什么指标达到上线标准？


---
> **滴滴**

算法题：209. 长度最小的子数组

xgb调参数调了哪些？xgb的学习率是什么？xgb的缺失值处理方式？xgb并行？xgb增益计算公式？

短信模型做了哪些迭代？

如果短信项目现在做，会用哪些模型？

deepFM模型介绍一下？

如何理解embedding？提到那篇经典的论文Real-time Personalization using Embeddings for Search Ranking at Airbnb

https://zhuanlan.zhihu.com/p/56128664

https://zhuanlan.zhihu.com/p/50081120

https://zhuanlan.zhihu.com/p/49537461


---
> **腾讯视频一面**

fm 内部如何处理不定长特征的

word2vec 的分层softmax和负采样分别是怎么优化训练速度的

算法：给定从小到大排列的数组，返回按绝对值排序的数组


---
> **便利蜂二面**

r2_score和皮尔逊相关系数区别？

c++中的map是不是线程安全的？


---
> **陌陌一面**

短信项目：做的过程中，做了哪些迭代？

为什么针对活跃用户和非活跃用户，要拆两个模型？这种拆分work后，有没有想过为什么？

代码题：word count


> **陌陌二面**

你们的推荐系统评价指标有哪些？只看ctr的话，会不会有什么问题，如果不只看ctr，你会定义什么指标？

现在排序用的xgb,如果抛开工程的限制，你会用哪些模型的来迭代？

你们的排序模型有没有用userid和itemid特征。

特征用了哪些？item量级，样本量级

xgb调过哪些参数？tf没怎么用过，我们这边用深度模型，那你怎么看待这种技能的不一样

如果上线了新模型，效果并没有提升怎么办。


---
> **学而思一面**

als、word2vec和fm都是怎么做的？

als 可调参数有哪些，如果确定的这些参数 向量维度，迭代次数，选择几个参数，线上看效果确定参数

word2vec 的序列是怎么做的，有没有做处理 去刷子序列，只取序列长度大于2的

fm特征有多少维，用户侧和item侧各有多少维 80维，用户侧和item侧各40维

召回项目中遇到的挑战，以及如何解决的 向量计算量太大，优化方案，聚类召回

除了线上的召回，有无尝试过其他召回 了解过双塔模型和youtube DNN 召回，未实践过

排序用的什么模型，为什么第一版就用deepfm？ deepfm，经主板和其他区几个业务线的测试，deepfm明显优于xgb版本，故直接上线deepfm做base版本

如何保证每日更新的特征和模型是稳定的 特征监控、模型监控以及数据效果报表

离线效果很好，但是上线之后不及预期，应如何解决？ 1.检查特征是否有穿越 2.线上线下打分是否一致 3.线上线下auc对比 4. 优化模型和特征

应该从哪几个方向考虑来优化效果

挖掘特征，包括离线特征和实时特征 2.模型版本迭代 3. 细化模型
大数据组件用过哪些，都在什么场景下会用到这些组件 hive、spark、flink、kafka、hdfs

代码题：hive sql， 每个用户购买最多的top3类别 row_number的使用

算法题：链表转置

---

